{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "098d9185",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43f0432",
   "metadata": {},
   "source": [
    "This notebook takes as input, the nfl_data_clean.csv file that is output from notebook Cap2_EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f29d77",
   "metadata": {},
   "source": [
    "# Contents:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cbb4c4",
   "metadata": {},
   "source": [
    "- module and function imports\n",
    "- load and inspect data\n",
    "- Fill NaNs and missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21984b48",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "720b3831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ced723",
   "metadata": {},
   "source": [
    "## Load and Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef17b981",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.read_csv('./data/nfl_data_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c4ba654",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>schedule_date</th>\n",
       "      <th>schedule_season</th>\n",
       "      <th>schedule_week</th>\n",
       "      <th>schedule_playoff</th>\n",
       "      <th>team_home</th>\n",
       "      <th>team_away</th>\n",
       "      <th>team_favorite_id</th>\n",
       "      <th>over_under_line</th>\n",
       "      <th>stadium_neutral</th>\n",
       "      <th>weather_temperature</th>\n",
       "      <th>weather_wind_mph</th>\n",
       "      <th>weather_humidity</th>\n",
       "      <th>weather_detail</th>\n",
       "      <th>home_id</th>\n",
       "      <th>away_id</th>\n",
       "      <th>home_pred_spread</th>\n",
       "      <th>home_ATS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>9/1/1979</td>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Tampa Bay Buccaneers</td>\n",
       "      <td>Detroit Lions</td>\n",
       "      <td>TB</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>79.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TB</td>\n",
       "      <td>DET</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>9/2/1979</td>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Buffalo Bills</td>\n",
       "      <td>Miami Dolphins</td>\n",
       "      <td>MIA</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>74.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BUF</td>\n",
       "      <td>MIA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>9/2/1979</td>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Chicago Bears</td>\n",
       "      <td>Green Bay Packers</td>\n",
       "      <td>CHI</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>78.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHI</td>\n",
       "      <td>GB</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 schedule_date  schedule_season schedule_week  schedule_playoff  \\\n",
       "0          12      9/1/1979             1979             1             False   \n",
       "1          13      9/2/1979             1979             1             False   \n",
       "2          14      9/2/1979             1979             1             False   \n",
       "\n",
       "              team_home          team_away team_favorite_id  over_under_line  \\\n",
       "0  Tampa Bay Buccaneers      Detroit Lions               TB             30.0   \n",
       "1         Buffalo Bills     Miami Dolphins              MIA             39.0   \n",
       "2         Chicago Bears  Green Bay Packers              CHI             31.0   \n",
       "\n",
       "   stadium_neutral  weather_temperature  weather_wind_mph  weather_humidity  \\\n",
       "0            False                 79.0               9.0              87.0   \n",
       "1            False                 74.0              15.0              74.0   \n",
       "2            False                 78.0              11.0              68.0   \n",
       "\n",
       "  weather_detail home_id away_id  home_pred_spread  home_ATS  \n",
       "0            NaN      TB     DET              -3.0      12.0  \n",
       "1            NaN     BUF     MIA               5.0       3.0  \n",
       "2            NaN     CHI      GB              -3.0       0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c400f23",
   "metadata": {},
   "source": [
    "## Fill NaNs and Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "196381f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill missing values for weather detail\n",
    "main_df['weather_detail'].fillna('none', inplace=True)\n",
    "\n",
    "# Calculate the mean values for each of the numeric weather columns\n",
    "mean_temperature = main_df['weather_temperature'].mean()\n",
    "mean_wind_mph = main_df['weather_wind_mph'].mean()\n",
    "mean_humidity = main_df['weather_humidity'].mean()\n",
    "\n",
    "# Fill NaN values with their respective means\n",
    "main_df['weather_temperature'].fillna(mean_temperature, inplace=True)\n",
    "main_df['weather_wind_mph'].fillna(mean_wind_mph, inplace=True)\n",
    "main_df['weather_humidity'].fillna(mean_humidity, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b75c2e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10953 entries, 0 to 10952\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Unnamed: 0           10953 non-null  int64  \n",
      " 1   schedule_date        10953 non-null  object \n",
      " 2   schedule_season      10953 non-null  int64  \n",
      " 3   schedule_week        10953 non-null  object \n",
      " 4   schedule_playoff     10953 non-null  bool   \n",
      " 5   team_home            10953 non-null  object \n",
      " 6   team_away            10953 non-null  object \n",
      " 7   team_favorite_id     10953 non-null  object \n",
      " 8   over_under_line      10953 non-null  float64\n",
      " 9   stadium_neutral      10953 non-null  bool   \n",
      " 10  weather_temperature  10953 non-null  float64\n",
      " 11  weather_wind_mph     10953 non-null  float64\n",
      " 12  weather_humidity     10953 non-null  float64\n",
      " 13  weather_detail       10953 non-null  object \n",
      " 14  home_id              10953 non-null  object \n",
      " 15  away_id              10953 non-null  object \n",
      " 16  home_pred_spread     10953 non-null  float64\n",
      " 17  home_ATS             10953 non-null  float64\n",
      "dtypes: bool(2), float64(6), int64(2), object(8)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#verify that there are no remaining NaNs\n",
    "main_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999b6ed1",
   "metadata": {},
   "source": [
    "## Handle each of the 'object' type fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1624decf",
   "metadata": {},
   "source": [
    "##### Change date col to instead be a count of number of days since superbowl 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dd3fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reformat date column to numeric, counting Superbowl 1 date as NFL 'Day 0'\n",
    "main_df['schedule_date'] = pd.to_datetime(main_df['schedule_date'])\n",
    "sb1_date = pd.to_datetime('1967-01-15')\n",
    "\n",
    "# Calculate the number of days elapsed for each date\n",
    "main_df['days_since_sb1'] = (main_df['schedule_date'] - sb1_date).dt.days\n",
    "\n",
    "# Drop the original 'schedule_date' column if you no longer need it\n",
    "main_df.drop('schedule_date', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cad7cf",
   "metadata": {},
   "source": [
    "##### Remove cols that do not add info to modeling/prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62938ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminate Team_home and team_away, as they are redundant with home_id away_id\n",
    "main_df.drop('team_home', axis=1, inplace=True)\n",
    "main_df.drop('team_away', axis=1, inplace=True)\n",
    "\n",
    "#eliminate team_favorite_id, as this information is fully captured in \n",
    "#   the sign of home_pred_spread column\n",
    "main_df.drop('team_favorite_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2375696b",
   "metadata": {},
   "source": [
    "##### Address schedule_week column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f156f9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n",
       "       '13', '14', '15', '16', 'Superbowl', '17', 'Wildcard', 'Division',\n",
       "       'Conference', '18'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.schedule_week.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943144af",
   "metadata": {},
   "source": [
    "Our approach will be to encode each of the non-numeric values to a consecutive number using domain knowledge that the NFL playoffs are played Wildcard, Division, Conference, then Superbowl. We'll use the new schedule from 2022 to define wildcard as 'week 19'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90a10deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n",
       "       '13', '14', '15', '16', '22', '17', '19', '20', '21', '18'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping for replacements\n",
    "replacement_mapping = {\n",
    "    'Wildcard': '19',\n",
    "    'Division': '20',\n",
    "    'Conference': '21',\n",
    "    'Superbowl': '22'\n",
    "}\n",
    "\n",
    "# Replace values in the 'schedule_week' column\n",
    "main_df['schedule_week'] = main_df['schedule_week'].replace(replacement_mapping)\n",
    "\n",
    "#verify above\n",
    "main_df.schedule_week.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37af0768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'schedule_week' column from strings to integers\n",
    "main_df['schedule_week'] = main_df['schedule_week'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9af3eb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10953 entries, 0 to 10952\n",
      "Data columns (total 15 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Unnamed: 0           10953 non-null  int64  \n",
      " 1   schedule_season      10953 non-null  int64  \n",
      " 2   schedule_week        10953 non-null  int64  \n",
      " 3   schedule_playoff     10953 non-null  bool   \n",
      " 4   over_under_line      10953 non-null  float64\n",
      " 5   stadium_neutral      10953 non-null  bool   \n",
      " 6   weather_temperature  10953 non-null  float64\n",
      " 7   weather_wind_mph     10953 non-null  float64\n",
      " 8   weather_humidity     10953 non-null  float64\n",
      " 9   weather_detail       10953 non-null  object \n",
      " 10  home_id              10953 non-null  object \n",
      " 11  away_id              10953 non-null  object \n",
      " 12  home_pred_spread     10953 non-null  float64\n",
      " 13  home_ATS             10953 non-null  float64\n",
      " 14  days_since_sb1       10953 non-null  int64  \n",
      "dtypes: bool(2), float64(6), int64(4), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "main_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c66880",
   "metadata": {},
   "source": [
    "##### Dummy encode home_id, away_id, and weather detail columns to make them ML friendly without losing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74099e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new main_df_numeric, where every dtype is float, int, or bool\n",
    "main_df_numeric = pd.get_dummies(main_df, columns=['home_id', 'away_id', 'weather_detail'], prefix=['home', 'away','weather_detail_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb78f8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main_df shape:            (10953, 15)\n",
      "main_df Dtypes:           [dtype('int64') dtype('bool') dtype('float64') dtype('O')] \n",
      "\n",
      "main_df_numeric shape:    (10953, 85)\n",
      "main_df_numeric Dtypes:   [dtype('int64') dtype('bool') dtype('float64')]\n"
     ]
    }
   ],
   "source": [
    "print('main_df shape:           ',main_df.shape)\n",
    "print('main_df Dtypes:          ',main_df.dtypes.unique(),'\\n')\n",
    "\n",
    "print('main_df_numeric shape:   ',main_df_numeric.shape)\n",
    "print('main_df_numeric Dtypes:  ',main_df_numeric.dtypes.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f352f1",
   "metadata": {},
   "source": [
    "# Extract Holdout Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2240743c",
   "metadata": {},
   "source": [
    "#### Isolate and remove data from the 2022 season"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d220677",
   "metadata": {},
   "source": [
    "2022 season is chosen because it is expected to be the most accurate approximation for the current/upcoming 2023 season, and this model is only prectically useful for prediction of the nearest upcoming games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37791e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284, 85)\n"
     ]
    }
   ],
   "source": [
    "#create df to keep the holdout data\n",
    "szn2022 = main_df_numeric[main_df_numeric.schedule_season == 2022]\n",
    "print(szn2022.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "800ee48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10669, 85)\n"
     ]
    }
   ],
   "source": [
    "main_df_numeric_mod = main_df_numeric[main_df_numeric.schedule_season != 2022]\n",
    "print(main_df_numeric_mod.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "830ae1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(main_df_numeric_mod.drop(columns='home_ATS'), \n",
    "                                                    main_df_numeric_mod.home_ATS, test_size=0.3, \n",
    "                                                    random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "982b941e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20118\n",
      "4612\n",
      "20104\n",
      "4613\n"
     ]
    }
   ],
   "source": [
    "print(max(X_train.days_since_sb1))\n",
    "print(min(X_train.days_since_sb1))\n",
    "print(max(X_test.days_since_sb1))\n",
    "print(min(X_test.days_since_sb1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198f399e",
   "metadata": {},
   "source": [
    "# note to self - TimeSeriesSplit method for CV?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614e4707",
   "metadata": {},
   "source": [
    "# Create Dummy Models for future Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506fb948",
   "metadata": {},
   "source": [
    "### create dumb_regressor model that always predicts the mean, and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "faaa2063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1765269789098877\n"
     ]
    }
   ],
   "source": [
    "true_home_ATS_mean = main_df.home_ATS.mean()\n",
    "print(true_home_ATS_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9c33f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8ed147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7408500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb48bb1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3728ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0682ccc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f30968",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
