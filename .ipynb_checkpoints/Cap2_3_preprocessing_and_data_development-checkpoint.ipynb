{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3be3f21",
   "metadata": {},
   "source": [
    "# NFL Betting Outcome Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379110da",
   "metadata": {},
   "source": [
    "Springboard Data Science Course Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210397a6",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Development - Notebook 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508de595",
   "metadata": {},
   "source": [
    "# Contents:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee64e58a",
   "metadata": {},
   "source": [
    "1. Imports\n",
    "2. Clean Data Formatting\n",
    "3. Extract Holdout Data\n",
    "4. Create Naive Model for Baseline Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d019a2",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "720b3831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.dummy import DummyRegressor, DummyClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58a18b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, accuracy_score, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe7d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.read_csv('./data/nfl_data_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52d65fb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>schedule_date</th>\n",
       "      <th>schedule_season</th>\n",
       "      <th>schedule_week</th>\n",
       "      <th>schedule_playoff</th>\n",
       "      <th>team_home</th>\n",
       "      <th>team_away</th>\n",
       "      <th>team_favorite_id</th>\n",
       "      <th>over_under_line</th>\n",
       "      <th>stadium_neutral</th>\n",
       "      <th>weather_temperature</th>\n",
       "      <th>weather_wind_mph</th>\n",
       "      <th>weather_humidity</th>\n",
       "      <th>weather_detail</th>\n",
       "      <th>home_id</th>\n",
       "      <th>away_id</th>\n",
       "      <th>home_pred_spread</th>\n",
       "      <th>home_ATS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>9/1/1979</td>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Tampa Bay Buccaneers</td>\n",
       "      <td>Detroit Lions</td>\n",
       "      <td>TB</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>79.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TB</td>\n",
       "      <td>DET</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>9/2/1979</td>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Buffalo Bills</td>\n",
       "      <td>Miami Dolphins</td>\n",
       "      <td>MIA</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>74.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BUF</td>\n",
       "      <td>MIA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>9/2/1979</td>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Chicago Bears</td>\n",
       "      <td>Green Bay Packers</td>\n",
       "      <td>CHI</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>78.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHI</td>\n",
       "      <td>GB</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 schedule_date  schedule_season schedule_week  schedule_playoff  \\\n",
       "0          12      9/1/1979             1979             1             False   \n",
       "1          13      9/2/1979             1979             1             False   \n",
       "2          14      9/2/1979             1979             1             False   \n",
       "\n",
       "              team_home          team_away team_favorite_id  over_under_line  \\\n",
       "0  Tampa Bay Buccaneers      Detroit Lions               TB             30.0   \n",
       "1         Buffalo Bills     Miami Dolphins              MIA             39.0   \n",
       "2         Chicago Bears  Green Bay Packers              CHI             31.0   \n",
       "\n",
       "   stadium_neutral  weather_temperature  weather_wind_mph  weather_humidity  \\\n",
       "0            False                 79.0               9.0              87.0   \n",
       "1            False                 74.0              15.0              74.0   \n",
       "2            False                 78.0              11.0              68.0   \n",
       "\n",
       "  weather_detail home_id away_id  home_pred_spread  home_ATS  \n",
       "0            NaN      TB     DET              -3.0      12.0  \n",
       "1            NaN     BUF     MIA               5.0       3.0  \n",
       "2            NaN     CHI      GB              -3.0       0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42114ce7",
   "metadata": {},
   "source": [
    "## 2. Clean Data Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d50931",
   "metadata": {},
   "source": [
    "### Fill NaNs and Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d449b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill missing values for weather detail\n",
    "main_df['weather_detail'].fillna('none', inplace=True)\n",
    "\n",
    "# Calculate the mean values for each of the numeric weather columns\n",
    "mean_temperature = main_df['weather_temperature'].mean()\n",
    "mean_wind_mph = main_df['weather_wind_mph'].mean()\n",
    "mean_humidity = main_df['weather_humidity'].mean()\n",
    "\n",
    "# Fill NaN values with their respective means\n",
    "main_df['weather_temperature'].fillna(mean_temperature, inplace=True)\n",
    "main_df['weather_wind_mph'].fillna(mean_wind_mph, inplace=True)\n",
    "main_df['weather_humidity'].fillna(mean_humidity, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9877fd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10953 entries, 0 to 10952\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Unnamed: 0           10953 non-null  int64  \n",
      " 1   schedule_date        10953 non-null  object \n",
      " 2   schedule_season      10953 non-null  int64  \n",
      " 3   schedule_week        10953 non-null  object \n",
      " 4   schedule_playoff     10953 non-null  bool   \n",
      " 5   team_home            10953 non-null  object \n",
      " 6   team_away            10953 non-null  object \n",
      " 7   team_favorite_id     10953 non-null  object \n",
      " 8   over_under_line      10953 non-null  float64\n",
      " 9   stadium_neutral      10953 non-null  bool   \n",
      " 10  weather_temperature  10953 non-null  float64\n",
      " 11  weather_wind_mph     10953 non-null  float64\n",
      " 12  weather_humidity     10953 non-null  float64\n",
      " 13  weather_detail       10953 non-null  object \n",
      " 14  home_id              10953 non-null  object \n",
      " 15  away_id              10953 non-null  object \n",
      " 16  home_pred_spread     10953 non-null  float64\n",
      " 17  home_ATS             10953 non-null  float64\n",
      "dtypes: bool(2), float64(6), int64(2), object(8)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#verify that there are no remaining NaNs\n",
    "main_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc77bb3",
   "metadata": {},
   "source": [
    "### Handle each of the 'object' type fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc8525d",
   "metadata": {},
   "source": [
    "##### Change date col to instead be a count of number of days since superbowl 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afe3c1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reformat date column to numeric, counting Superbowl 1 date as NFL 'Day 0'\n",
    "main_df['schedule_date'] = pd.to_datetime(main_df['schedule_date'])\n",
    "sb1_date = pd.to_datetime('1967-01-15')\n",
    "\n",
    "# Calculate the number of days elapsed for each date\n",
    "main_df['days_since_sb1'] = (main_df['schedule_date'] - sb1_date).dt.days\n",
    "\n",
    "# Drop the original 'schedule_date' column if you no longer need it\n",
    "main_df.drop('schedule_date', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62197c02",
   "metadata": {},
   "source": [
    "##### Remove cols that do not add info to modeling/prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbb92953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminate Team_home and team_away, as they are redundant with home_id away_id\n",
    "main_df.drop('team_home', axis=1, inplace=True)\n",
    "main_df.drop('team_away', axis=1, inplace=True)\n",
    "\n",
    "#eliminate team_favorite_id, as this information is fully captured in \n",
    "#   the sign of home_pred_spread column\n",
    "main_df.drop('team_favorite_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca451230",
   "metadata": {},
   "source": [
    "##### Address schedule_week column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8319ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n",
       "       '13', '14', '15', '16', 'Superbowl', '17', 'Wildcard', 'Division',\n",
       "       'Conference', '18'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.schedule_week.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920c8d92",
   "metadata": {},
   "source": [
    "Our approach will be to encode each of the non-numeric values to a consecutive number using domain knowledge that the NFL playoffs are played Wildcard, Division, Conference, then Superbowl. We'll use the new schedule from 2022 to define wildcard as 'week 19'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6214432e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n",
       "       '13', '14', '15', '16', '22', '17', '19', '20', '21', '18'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping for replacements\n",
    "replacement_mapping = {\n",
    "    'Wildcard': '19',\n",
    "    'Division': '20',\n",
    "    'Conference': '21',\n",
    "    'Superbowl': '22'\n",
    "}\n",
    "\n",
    "# Replace values in the 'schedule_week' column\n",
    "main_df['schedule_week'] = main_df['schedule_week'].replace(replacement_mapping)\n",
    "\n",
    "#verify above\n",
    "main_df.schedule_week.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "230d4cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'schedule_week' column from strings to integers\n",
    "main_df['schedule_week'] = main_df['schedule_week'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7736d123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10953 entries, 0 to 10952\n",
      "Data columns (total 15 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Unnamed: 0           10953 non-null  int64  \n",
      " 1   schedule_season      10953 non-null  int64  \n",
      " 2   schedule_week        10953 non-null  int64  \n",
      " 3   schedule_playoff     10953 non-null  bool   \n",
      " 4   over_under_line      10953 non-null  float64\n",
      " 5   stadium_neutral      10953 non-null  bool   \n",
      " 6   weather_temperature  10953 non-null  float64\n",
      " 7   weather_wind_mph     10953 non-null  float64\n",
      " 8   weather_humidity     10953 non-null  float64\n",
      " 9   weather_detail       10953 non-null  object \n",
      " 10  home_id              10953 non-null  object \n",
      " 11  away_id              10953 non-null  object \n",
      " 12  home_pred_spread     10953 non-null  float64\n",
      " 13  home_ATS             10953 non-null  float64\n",
      " 14  days_since_sb1       10953 non-null  int64  \n",
      "dtypes: bool(2), float64(6), int64(4), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "main_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00efc0c",
   "metadata": {},
   "source": [
    "##### Dummy encode home_id, away_id, and weather detail columns to make them ML friendly without losing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e4db6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new main_df_numeric, where every dtype is float, int, or bool\n",
    "main_df_numeric = pd.get_dummies(main_df, columns=['home_id', 'away_id', 'weather_detail'], prefix=['home', 'away','weather_detail_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afe3d2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main_df shape:            (10953, 15)\n",
      "main_df Dtypes:           [dtype('int64') dtype('bool') dtype('float64') dtype('O')] \n",
      "\n",
      "main_df_numeric shape:    (10953, 85)\n",
      "main_df_numeric Dtypes:   [dtype('int64') dtype('bool') dtype('float64')]\n"
     ]
    }
   ],
   "source": [
    "print('main_df shape:           ',main_df.shape)\n",
    "print('main_df Dtypes:          ',main_df.dtypes.unique(),'\\n')\n",
    "\n",
    "print('main_df_numeric shape:   ',main_df_numeric.shape)\n",
    "print('main_df_numeric Dtypes:  ',main_df_numeric.dtypes.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dc5557",
   "metadata": {},
   "source": [
    "## 3. Extract Holdout Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4b9cd5",
   "metadata": {},
   "source": [
    "#### Isolate and remove data from the 2022 season"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd65dd8",
   "metadata": {},
   "source": [
    "2022 season is chosen because it is expected to be the most accurate approximation for the current/upcoming 2023 season, and this model is only prectically useful for prediction of the nearest upcoming games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bfe442f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284, 85)\n"
     ]
    }
   ],
   "source": [
    "#create df to keep the holdout data\n",
    "szn2022 = main_df_numeric[main_df_numeric.schedule_season == 2022]\n",
    "print(szn2022.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "620ae029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10669, 85)\n"
     ]
    }
   ],
   "source": [
    "main_df_numeric_mod = main_df_numeric[main_df_numeric.schedule_season != 2022]\n",
    "print(main_df_numeric_mod.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5debf802",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(main_df_numeric_mod.drop(columns='home_ATS'), \n",
    "                                                    main_df_numeric_mod.home_ATS, test_size=0.3, \n",
    "                                                    random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0bebab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20118\n",
      "4612\n",
      "20104\n",
      "4613\n"
     ]
    }
   ],
   "source": [
    "print(max(X_train.days_since_sb1))\n",
    "print(min(X_train.days_since_sb1))\n",
    "print(max(X_test.days_since_sb1))\n",
    "print(min(X_test.days_since_sb1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7a377d",
   "metadata": {},
   "source": [
    "## 4. Create Naive Model for Baseline Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287ef5f4",
   "metadata": {},
   "source": [
    "### Create naive regressor model that always predicts the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8b92121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2836770219603642\n"
     ]
    }
   ],
   "source": [
    "true_home_ATS_mean = y_train.mean()\n",
    "print(true_home_ATS_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e8b2381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28367702]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dumb_reg = DummyRegressor(strategy='mean')\n",
    "dumb_reg.fit(X_train, y_train)\n",
    "\n",
    "#to verify that it matches the mean above\n",
    "dumb_reg.constant_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990b033e",
   "metadata": {},
   "source": [
    "### Evaluate naive regressor using various metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bb408d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared (R2) score on training data: 0.0\n",
      "Mean Absolute Error (MAE) on training data: 10.487060807777173\n",
      "Mean Squared Error (MSE) on training data: 180.01168722937558\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.metrics import r2_score\n",
    "\n",
    "y_pred_train = dumb_reg.predict(X_train)\n",
    "\n",
    "# Calculate the R-squared and MAE\n",
    "r2_dummy = r2_score(y_train, y_pred_train)\n",
    "mae_dummy = mean_absolute_error(y_train, y_pred_train)\n",
    "mse_dummy = mean_squared_error(y_train, y_pred_train)\n",
    "\n",
    "# Print the R2 score\n",
    "print(\"R-squared (R2) score on training data:\", r2_dummy)\n",
    "print(\"Mean Absolute Error (MAE) on training data:\", mae_dummy)\n",
    "print(\"Mean Squared Error (MSE) on training data:\", mse_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ce07a5",
   "metadata": {},
   "source": [
    "### Create naive binary classifier that always predicts that the home team will win, i.e. the home_ATS column is positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0af3f0",
   "metadata": {},
   "source": [
    "This may be valuable, because in future modeling, both regressors and binary classifiers will be applied to this dataset to see which can best predict outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0f8409",
   "metadata": {},
   "source": [
    "The first order of business to accomplish this task will be to create a y_train df that is a binary classifier, instead of a semi-continuous variable. This can be accomplished by encoding home_ATS > 0 to the True, or positive case, and home_ATS < 0 to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bb1fd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create binary response variable y_train_binary\n",
    "y_train_binary = pd.DataFrame({'y_binary': (y_train > 0).astype(int)})\n",
    "#y_train_binary.head(10)\n",
    "\n",
    "#do the same for y_test\n",
    "y_test_binary = pd.DataFrame({'y_binary': (y_test > 0).astype(int)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01677380",
   "metadata": {},
   "outputs": [],
   "source": [
    "dumb_clas = DummyClassifier(strategy='constant', constant=1)\n",
    "dumb_clas.fit(X_train, y_train_binary)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_binary = dumb_clas.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f485b54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4739144017494533\n",
      "Confusion Matrix:\n",
      "[[   0 1684]\n",
      " [   0 1517]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate dummy classifier's accuracy\n",
    "\n",
    "accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "confusion = confusion_matrix(y_test_binary, y_pred_binary)\n",
    "\n",
    "# Print\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0d796b",
   "metadata": {},
   "source": [
    "Unsurprisingly, both versions of naive models perform poorly, actually worse than 50% accuracy based on the above train_test_split. These will serve as solid foundations for future model comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a433d12b",
   "metadata": {},
   "source": [
    "## Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c7154c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply StandardScaler directly to the entire DataFrame\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "y_train_scaled = scaler.fit_transform(y_train.array.reshape(-1, 1))\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "y_test_scaled = scaler.fit_transform(y_test.array.reshape(-1, 1))\n",
    "\n",
    "# Convert the scaled result back to a DataFrame\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "y_train_scaled = pd.DataFrame(y_train_scaled, columns=['home_ATS'])\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "y_test_scaled = pd.DataFrame(y_test_scaled, columns=['home_ATS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760ab350",
   "metadata": {},
   "source": [
    "### Export files for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b7adb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.to_csv('./data/X_train_scaled')\n",
    "y_train_scaled.to_csv('./data/y_train_scaled')\n",
    "X_test_scaled.to_csv('./data/X_test_scaled')\n",
    "y_test_scaled.to_csv('./data/y_test_scaled')\n",
    "\n",
    "X_train.to_csv('./data/X_train')\n",
    "y_train.to_csv('./data/y_train')\n",
    "X_test.to_csv('./data/X_test')\n",
    "y_test.to_csv('./data/y_test')\n",
    "\n",
    "main_df_numeric.to_csv('./data/main_df_numeric')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
